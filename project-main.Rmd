---
title: "Co-movement and Growth in Housing Markets: from PCA to cointegration and factor models"
author: "Yiran Yao"
date: "2025-08-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      fig.align = "center",
                      fig.width = 10, 
                      fig.height = 5
                      )
```

```{r library}
library(tidyverse)
library(janitor)
library(lubridate)
library(forecast)
library(fpp3)
library(urca)
library(broom)
library(tseries)
library(scales)
library(slider)
library(kableExtra)
library(patchwork)
#library(plotly)
```

```{r load-clean-data}
city_indexes <- read_csv("data/city_indexes.csv")
factor_trends <- read_csv("data/df_factor_trends.csv")
reg_coefs <- read_csv("data/df_reg_coefs.csv")

pcs <- read_csv("data/df_pcs.csv")
eofs_city <- read_csv("data/df_eofs_city.csv")
eofs <- read_csv("data/df_eofs.csv")

city_indexes <- city_indexes |> 
  clean_names() 
```


# Introduction 

Traditional approaches to analysing housing indexes, such as hedonic or repeat-sales models, can introduce selection bias or violate underlying assumptions. Moreover, they fail to capture key regional, social, or macroeconomic factors that play a significant role in driving housing price movements.

In the recent research Sijp et al. (2025) propose a new approach that applies Principal Component Analysis (PCA) to city-level housing indexes, enabling the extraction of key drivers of price movements and offering a deeper understanding of the forces shaping housing markets.

The PCA results show that the first three principal components capture much of the behaviour of local price indexes, as a linear combination of their time series explains most of the variance in the housing index. Nevertheless, the PCA-based linear model lacks robustness across different time windows, and its coefficient estimates must be derived directly from the PCA procedure.

Our exploratory research extends the PCA approach by addressing these limitations through a factor linear model, which uses time series data directly, with independent variables serving as proxies for the PCA-derived principal components.


# Research Structure 

The national trend (U) exhibits a close correspondence with PC1 (market), while the Brisbane–Sydney spread (δBS) aligns with PC2 (mining). Given that these principal components account for the majority of variance in the index, our preliminary analysis focuses on U and δBS, with subsequent extensions planned.

The research will focus on the following directions: 

* Examine the characteristics of U and δBS. 

* Evaluate whether the existing U-adjusted δBS should be employed in place of the “Brisbane on Sydney” spread derived from the bris ∼ syd regression for modelling purposes.

* Whether the δBS serves as a more stable measure than U in the factor model.

* Whether the coefficient δ provides a valid replacement for PC2.

* How well the factor model captures the variation in individual SA4 indexes.

* How the model can be extended to a time-dependent version using moving windows with evolving coefficients.


## Exploratory Analysis 

The exploratory analysis utilises visualisations to characterise the dynamics of the national trend (U) and the Brisbane–Sydney spread (δBS), thereby clarifying their underlying properties.

```{r}
factor_trend_ts <- factor_trends |>
  transmute(
    month_date = yearmonth(as.Date(month_date)),
    U = as.numeric(market),
    BS = as.numeric(mining)
  ) |>
  as_tsibble(index = month_date)

# Time-series autoplot
p1 <- factor_trend_ts |> autoplot(U) + labs(title = "U: National Trend", x = "Month", y = "Index")
p2 <- factor_trend_ts |> autoplot(BS) + labs(title = "δBS: Brisbane–Sydney Spread", x = "Month", y = "Index")
p1 + p2
```

**Time plots:** 

* U rises steadily from 2003 to 2012, transitions into a slower growth phase until 2019, then undergoes a sharp regime shift during 2020–2022 (the COVID period) followed by persistently elevated and volatile levels, with growth rates remaining time-varying throughout.

* δBS displays a prolonged, uneven rise from 2003 to 2012, followed by a sharp regime shift, then COVID-related fluctuations, with the level adjusting and showing time-varying patterns.

```{r}
# Seasonal plots
p3  <- factor_trend_ts |> gg_season(U) + labs(title = "Seasonal Plot: U", x = "Month", y = "Index")
p4 <- factor_trend_ts |> gg_season(BS) + labs(title = "Seasonal Plot: δBS", x = "Month", y = "Index")
p3 + p4
```

**Seasonal plots:**

* U has apparent within-year slopes being dominated by the strong upward trend; no systematic month-of-year effects.

* δBS shows little evidence of month-to-month seasonality, with no particular month standing out, though its overall level varies between years.

```{r}
# Seasonal subseries
p5 <- factor_trend_ts |> gg_subseries(U) + labs(title = "Seasonal Subseries: U", x = "Month", y = "Index")
p6 <- factor_trend_ts |> gg_subseries(BS) + labs(title = "Seasonal Subseries: δBS", x = "Month", y = "Index")
p5 + p6
```

**Seasonal sub-series plot:** 

* Each monthly panel of U shows a steady upward rise with mean value across months remaining similar, reinforcing that the series is driven more by trend than by seasonality.

* The δBS seasonal sub-series plot reinforces the lack of a dominant seasonal pattern, as the monthly profiles are similar in shape and the corresponding means remain relatively flat and close to zero.

```{r}
# ACF
p7  <- factor_trend_ts |> ACF(U) |> autoplot() + labs(title = "ACF: U", x = "Lag", y = "ACF")
p8 <- factor_trend_ts |> ACF(BS) |> autoplot() + labs(title = "ACF: δBS", x = "Lag", y = "ACF")
p7 + p8
```

**ACF plot:** 

* Both series has very high autocorrelation with slow decay across many lags, indicating strong dependence on many prior months, though the variation of δBS is much more bounded than U. 


## Cointegration Test on Price Index between Brisbane and Sydney 

We use the Engle–Granger procedure to test whether the **raw Brisbane and Sydney price index** (from `city_index` data set) levels are cointegrated, that is - whether each series is non-stationary but some linear combination is stationary, implying a stable long-run relationship. 

The purpose of this test is to decide whether to regress the raw Brisbane index (μ Brisbane) on the raw Sydney index (μ Sydney) to obtain the coefficient, or to continue using the current δBS, which is derived by regressing the Sydney and Brisbane price indexes on the national trend U first.

```{r}
# Build monthly series of levels
city <- city_indexes |>
  transmute(
    month = yearmonth(floor_date(as.Date(month_date), "month")),
    bris  = as.numeric(greater_brisbane),
    syd   = as.numeric(greater_sydney)
  ) |>
  as_tsibble(index = month) 

# Unit-root checks
adf_bris_lvl  <- ur.df(city$bris, type = "trend", selectlags = "AIC")
adf_syd_lvl   <- ur.df(city$syd,  type = "trend", selectlags = "AIC")
adf_bris_diff <- ur.df(diff(city$bris), type = "none", selectlags = "AIC")
adf_syd_diff  <- ur.df(diff(city$syd),  type = "none", selectlags = "AIC")

# Long-run regression
cn_lm <- lm(bris ~ syd, data = as.data.frame(city))  
alpha <- coef(cn_lm)[2]
ect   <- resid(cn_lm)  

# ADF on residuals 
adf_ect <- ur.df(ect, type = "none", selectlags = "AIC")
summary(adf_ect)
```

The test statistic is –1.098, so we fail to reject the unit-root null. This result indicates no cointegration between the raw Brisbane and Sydney levels and the residuals are non-stationary, which means a single long-run equilibrium is not supported.

We therefore model a factor model and treat the current δBS as an informative second factor (a proxy for PC2), rather than assuming a tight long-run equilibrium between Brisbane and Sydney levels.

## Sydney-Brisbane Spread vs National Trend

To justify including δBS alongside the national trend U in the factor model, we need to show that δBS is more bounded over time, meaning it stays within a narrower range and has lower long-term volatility.

We approach this assumption from 3 angles:

* Method One uses past volatility and spread measures to compare past fluctuations in δBS and U. It is straightforward, does not rely on a model, and gives a clear historical picture.

* Method Two fits ARIMA models to both series and compares the width of 10-year forecast intervals. This gives a forward-looking view using well-known time series methods.

* Method Three runs simulation-based forecasts to estimate the possible future range of each series. This can capture uncertainty beyond ARIMA’s limits and show patterns like non-linear or extreme swings.

Combined, these methods integrate descriptive analysis, statistical modelling, and stochastic simulation to rigorously assess whether δBS is more bounded than U.

### 1. Statistical Comparison 

In the first part, we compared δBS and U using overall statistics and rolling-window measures.

* The global summary (entire time period) of δBS and U covered several different measures, each of them captures different aspect of spread. The statistics includes: 
  * Standard deviation: The average distance of each observation to the series mean. If δBS has a smaller standard deviation than U, it indicates that δBS is more stable and less volatile over the entire period.
  * Interquartile range: The spread of the medium 50% of the data, if δBS has a tighter interquartile range than U, then it is generally more stable. 
  * Median absolute deviation: The median of absolute deviations from the mean. This measure is more robust to outliers. If the value of δBS is lower than U, it indicates that δBS has less extreme fluctuations.
  * Total range: The difference between the maximum and minimum values in the series, which examines the extreme swings in the series.  

We next applied rolling windows of 12 and 24 months to the same statistics. Rather than using the entire time span at once, this approach slides a fixed-length window along the series, calculating the variability measures at each step using only the most recent 12 or 24 months of data. This method highlights how the volatility and dispersion of δBS and U evolve over time. 

We use 12-month windows to smooth short-term fluctuations and capture typical annual housing cycles, helping assess if volatility is bounded within a year. The 24-month windows extend the view, showing whether this boundedness holds beyond yearly patterns and reflecting medium-term events.

To keep the report concise, we highlight two plots: the 12-month rolling standard deviation for short-term volatility and the 24-month rolling range for longer-term fluctuations.

Finally, we calculated the proportion of time (by 12 and 24 months respectively) in which δBS had a lower spread than U, giving a simple measure of how often it was more bounded.

```{r}
# Load df 
factor_trends_ana <- factor_trends |>
  select(month_date, U = market, BS = mining) 

# Global comparison - full period 
global_summary <- factor_trends_ana |>
  summarise(
    sd_U = sd(U),
    sd_BS = sd(BS),
    var_U = var(U),
    var_BS = var(BS),
    iqr_U = IQR(U),
    iqr_BS = IQR(BS),
    range_U = diff(range(U)),
    range_BS = diff(range(BS)),
    mad_U = mad(U, center = median(U)),
    mad_BS = mad(BS, center = median(BS))
  ) 

global_ratio <- global_summary |>
  mutate(
    sd_ratio_BS_over_U = sd_BS / sd_U,
    iqr_ratio_BS_over_U = iqr_BS / iqr_U,
    mad_ratio_BS_over_U = mad_BS / mad_U,
    rng_ratio_BS_over_U = range_BS / range_U
  ) |>
  select(sd_ratio_BS_over_U,
         iqr_ratio_BS_over_U,
         mad_ratio_BS_over_U,
         rng_ratio_BS_over_U) 

kable(global_ratio, caption = "Global Summary Statistics") 

# Summary tables 
#print(global_summary) 
#print(global_ratio)
```

The global ratios are all well below 1, meaning δBS has consistently lower spread than U across all four measures. This supports δBS being more bounded overall.

```{r}
# Rolling window config (12 and 24 months) 
w12 <- 12
w24 <- 24

# Functions for rolling statistics (SD, IQR, Range)
roll_sd   <- function(x, k)
  slide_dbl(x, sd, .before = k - 1, .complete = TRUE)

roll_iqr  <- function(x, k)
  slide_dbl(x, IQR, .before = k - 1, .complete = TRUE)

roll_rng  <- function(x, k)
  slide_dbl(x, function(vec)
    diff(range(vec)), .before = k - 1, .complete = TRUE)

# Compute rolling statistics
roll_stats <- factor_trends_ana |>
  mutate(
    # 12-month window
    sd12_U = roll_sd(U, w12),
    iqr12_U = roll_iqr(U, w12),
    rng12_U = roll_rng(U, w12),
    sd12_BS = roll_sd(BS, w12),
    iqr12_BS = roll_iqr(BS, w12),
    rng12_BS = roll_rng(BS, w12),
    # 24-month window
    sd24_U = roll_sd(U, w24),
    iqr24_U = roll_iqr(U, w24),
    rng24_U = roll_rng(U, w24),
    sd24_BS = roll_sd(BS, w24),
    iqr24_BS = roll_iqr(BS, w24),
    rng24_BS = roll_rng(BS, w24)
  )
```

```{r}
# Rolling 12-month SD plot 
sd12_long <- roll_stats |>
  select(month_date, sd12_U, sd12_BS) |>
  pivot_longer(-month_date, names_to = "series", values_to = "sd12") 

ggplot(sd12_long, aes(month_date, sd12, color = series)) +
  geom_line() +
  labs(
    title = "Rolling 12-month Standard Deviation (SD)",
    subtitle = "Lower values show less volatility over a 12-month period",
    x = "Year",
    y = "SD"
  ) +
  theme_minimal()

# Rolling 24-month Range plot 
rng24_long <- roll_stats |>
  select(month_date, rng24_U, rng24_BS) |>
  pivot_longer(-month_date, names_to = "series", values_to = "rng24") 

ggplot(rng24_long, aes(month_date, rng24, color = series)) +
  geom_line() +
  labs(
    title = "Rolling 24-month Range",
    subtitle = "Wider range means bigger swings over the period",
    x = "Year", y = "Range"
  ) +
  theme_minimal()

# Summary table 
porp_summary <- tibble(
  period = c("12-month", "24-month"),
  prop_lower_sd = c(
    mean(roll_stats$sd12_BS < roll_stats$sd12_U, na.rm = TRUE),
    mean(roll_stats$sd24_BS < roll_stats$sd24_U, na.rm = TRUE)
  ),
  prop_lower_iqr = c(
    mean(roll_stats$iqr12_BS < roll_stats$iqr12_U, na.rm = TRUE),
    mean(roll_stats$iqr24_BS < roll_stats$iqr24_U, na.rm = TRUE)
  ),
  prop_lower_rng = c(
    mean(roll_stats$rng12_BS < roll_stats$rng12_U, na.rm = TRUE),
    mean(roll_stats$rng24_BS < roll_stats$rng24_U, na.rm = TRUE)
  )
)

kable(porp_summary, digits = 3, caption = "Proportion of Time δBS < U in Rolling Windows")
```

While the rolling-window plots and statistics give a more detailed picture: 

* The 12-month rolling standard deviation plot shows that δBS is often less volatile than U, but not consistently (occasional spikes narrow the gap).

* The 24-month rolling range plot shows δBS has wider swings at times, but also periods where it is more stable than U, highlighting its tendency to avoid large swings over longer periods.

* δBS has a lower spread than U in around 38.6% of the time for 12-month windows and 41.0% for 24-month windows, indicating it is more bounded (however less than half the time) in rolling windows.

### 2. ARIMA Forecasting Comparison

Following the descriptive analysis, in this section, we take a model-based approach to assess boundedness. 

We applied auto ARIMA to both δBS and U time series to produce 10-year ahead forecasts, with the sole purpose of comparing their long-term prediction interval widths. 

**Using auto selection ensures each series is modelled appropriately without over-focusing on manual parameter tuning, keeping the emphasis on interval comparison as a measure of future boundedness.**

```{r}
# Transform df to tsibble 
factor_trends_ts <- factor_trends |>
  transmute(date = yearmonth(month_date),
            U  = market,
            BS = mining) |> 
  as_tsibble(index = date)

# Fit ARIMA models 
fit_U <- factor_trends_ts |>
  model(
    auto_U = ARIMA(U),
    rw_drift  = ARIMA(U ~ 1 + pdq(0,1,0) + PDQ(0,0,0))
  )

fit_BS <- factor_trends_ts |>
  model(auto_BS = ARIMA(BS ~ pdq() + PDQ(0,0,0))) # exclude seasonality 

# Compare AICc values
fit_U |>
  select(auto_U, rw_drift) |>
  glance() |>
  select(model = .model, AICc) 
```

The auto ARIMA model selected ARIMA(0,2,0)(2,0,0)[12] for the national trend U and ARIMA(1,1,2) for the Brisbane–Sydney spread δBS. We have also examined the residuals of both fitted models, which appear to be white noise, indicating that the models adequately capture the underlying dynamics of both series.

Since applying two levels of differencing implies a quadratic trend, it may indicate over-differencing for an economic series that exhibits drift. Our visual inspection already suggests the presence of drift, and an Augmented Dickey–Fuller test (run separately) further confirms this with a Phi statistic significant at the 5% level. To avoid clutter, we do not include the test output in this report.

Given this, we manually fitted an ARIMA(0,1,0) model with a constant (random walk with drift) in parallel for U and compared its AICc value against the auto-selected ARIMA model. The auto ARIMA model is objectively better by AICc and diagnostics, so we will report the auto ARIMA for completeness but also include an ARIMA(1,0,1) with a constant as a benchmark for comparison since it has a stronger intuition. 

```{r}
# Forecast - 10 years
h <- 120
fc_U  <- forecast(fit_U,  h = h, level = c(80, 95))
fc_BS <- forecast(fit_BS, h = h, level = c(80, 95))

# Compute average forecast intervals 
fc_int <- function(fc, level) {
  col <- fc$level == level
  mean(fc$upper[, col] - fc$lower[, col])
}

summary_fc_int<- tibble(
  period_months = h,
  level = c(80, 95),
  mean_int_U = c(fc_int(fc_U, 80), fc_int(fc_U, 95)),
  mean_int_BS = c(fc_int(fc_BS, 80), fc_int(fc_BS, 95))
) 

# kable(summary_fc_int, caption = "Average Forecast Intervals for δBS and U")

# Plot the forecasts
autoplot(fc_U, factor_trends_ts)
autoplot(fc_BS, factor_trends_ts) 
```

From the forecast fan plot, we can first see that the random walk with drift produces very narrow forecast intervals, because it assumes only linear variance growth with horizon and ignores short-run autocorrelation. By contrast, the auto-ARIMA specification captures AR and MA dynamics, which propagate uncertainty further into the future, resulting in wider intervals. 

The two alternative models for the national trend U lead to very different conclusions when compared with δBS. The random walk with drift produces unrealistically narrow intervals, while the auto-ARIMA specification not only achieves a much lower AICc but also yields forecast intervals that better reflect the underlying uncertainty. For this reason, we continue with the auto-ARIMA model in our boundedness comparison.

Based on the average 10-year forecast ranges, the δBS spread consistently shows narrower prediction intervals than the national trend U. This indicates that the spread is likely to remain more contained over the next decade, a conclusion supported by both the summary statistics and the forecast visualisations.

### 3. Simulation-Based Forecasting

Next,We extend the analysis by applying simulation-based forecasting using bootstrap simulations on the fitted auto-ARIMA models for both the national index U and the Brisbane–Sydney spread δBS. A total of 5,000 sample paths were generated over the forecast horizon. This approach enables the capture of more complex dynamics and potential non-linearities that standard ARIMA models may overlook.

Bootstrap simulation involves repeatedly resampling the residuals from the fitted ARIMA model and feeding them forward through the model structure. Each resample generates a single plausible future path of the index. 

By replicating this procedure thousands of times, we build up an empirical distribution of possible forecast trajectories. From this simulated distribution, we can then extract measures such as forecast intervals, the interval widths and probabilities that entire forecast paths stay within specified historical bounds.

```{r}
set.seed(123)

# Simulation 
n <- 5000 
sim_U  <- fit_U |> 
  select(auto_U) |> 
  generate(h = h, times = n, bootstrap = TRUE)

sim_BS <- fit_BS %>%
  generate(h = h, times = n, bootstrap = TRUE)
```

```{r}
bands_U <- sim_U %>%
  as_tibble() %>%
  group_by(date) %>%
  summarise(
    p50  = median(.sim, na.rm = TRUE),
    lo80 = quantile(.sim, 0.10, na.rm = TRUE),
    hi80 = quantile(.sim, 0.90, na.rm = TRUE),
    lo95 = quantile(.sim, 0.025, na.rm = TRUE),
    hi95 = quantile(.sim, 0.975, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(width80 = hi80 - lo80, width95 = hi95 - lo95) %>%
  mutate(series = "U")

bands_BS <- sim_BS %>%
  as_tibble() %>%
  group_by(date) %>%
  summarise(
    p50  = median(.sim, na.rm = TRUE),
    lo80 = quantile(.sim, 0.10, na.rm = TRUE),
    hi80 = quantile(.sim, 0.90, na.rm = TRUE),
    lo95 = quantile(.sim, 0.025, na.rm = TRUE),
    hi95 = quantile(.sim, 0.975, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(width80 = hi80 - lo80, width95 = hi95 - lo95) %>%
  mutate(series = "δBS")

# End of horizon fan widths
end_widths <- bind_rows(bands_U, bands_BS) |> 
  slice_max(order_by = date, n = 1, by = series) |> 
  select(series, width80, width95)

kable(end_widths, caption = "End of Horizon Fan Widths for δBS and U")
```

The fan width at the end of the forecast horizon indicates that the uncertainty of U is approximately nine times greater than that of δBS.

```{r}
# Stay in historical 90% band prob 
lo_U  <- quantile(factor_trends_ts$U,  0.05, na.rm = TRUE)
hi_U  <- quantile(factor_trends_ts$U,  0.95, na.rm = TRUE)
lo_BS <- quantile(factor_trends_ts$BS, 0.05, na.rm = TRUE)
hi_BS <- quantile(factor_trends_ts$BS, 0.95, na.rm = TRUE)

pr_U <- sim_U |>
  as_tibble() |>
  group_by(.rep) |>
  summarise(
    path_min = min(.sim, na.rm = TRUE),
    path_max = max(.sim, na.rm = TRUE),
    .groups = "drop"
  ) |>
  summarise(stay_90 = mean(path_min >= lo_U & path_max <= hi_U)) %>%
  pull(stay_90)

pr_BS <- sim_BS |>
  as_tibble() |>
  group_by(.rep) |>
  summarise(
    path_min = min(.sim, na.rm = TRUE),
    path_max = max(.sim, na.rm = TRUE),
    .groups = "drop"
  ) |>
  summarise(stay_90 = mean(path_min >= lo_BS &
                             path_max <= hi_BS)) %>%
  pull(stay_90)

stay_prob_tbl <- tibble(
  series = c("U", "δBS"),
  stay_90 = c(pr_U, pr_BS)
)

kable(stay_prob_tbl, caption = "Probability of Staying in Historical 90% Band")
```

δBS exhibits a 26.0% probability of remaining within its historical 90% confidence band, whereas U demonstrates a 0% probability. 

```{r}
# MAD over horizon 
last_U  <- factor_trends_ts |> slice_max(date, n = 1) |> pull(U)
last_BS <- factor_trends_ts |> slice_max(date, n = 1) |> pull(BS)

devs_U <- sim_U |>
  group_by(.rep) |>
  summarise(max_dev = max(abs(.sim - last_U), na.rm = TRUE), .groups = "drop")

devs_BS <- sim_BS |>
  group_by(.rep) |>
  summarise(max_dev = max(abs(.sim - last_BS), na.rm = TRUE), .groups = "drop")

md_U_median <- median(devs_U$max_dev, na.rm = TRUE)
md_U_p90    <- quantile(devs_U$max_dev, 0.90, na.rm = TRUE)

md_BS_median <- median(devs_BS$max_dev, na.rm = TRUE)
md_BS_p90    <- quantile(devs_BS$max_dev, 0.90, na.rm = TRUE)

max_dev_tbl <- tibble::tibble(
  series         = c("U", "δBS"),
  median_max_dev = c(md_U_median, md_BS_median),
  p90_max_dev    = c(md_U_p90,    md_BS_p90)
)

kable(max_dev_tbl, caption = "Maximum Deviation Statistics for δBS and U")
```

Over the forecast horizon, the mean absolute deviation indicates that δBS exhibits both a lower median deviation and a lower 90th-percentile maximum deviation compared to U.
