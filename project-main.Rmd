---
title: "Co-movement and Growth in Housing Markets: from PCA to cointegration and factor models"
author: "Yiran Yao"
date: "2025-08-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      fig.align = "center",
                      fig.width = 10, 
                      fig.height = 5
                      )
```

```{r library}
library(tidyverse)
library(janitor)
library(lubridate)
library(forecast)
library(fpp3)
library(urca)
library(broom)
library(tseries)
library(scales)
library(slider)
library(kableExtra)
library(patchwork)
#library(plotly)
```

```{r load-clean-data}
city_indexes <- read_csv("data/city_indexes.csv")
factor_trends <- read_csv("data/df_factor_trends.csv")
reg_coefs <- read_csv("data/df_reg_coefs.csv")

pcs <- read_csv("data/df_pcs.csv")
eofs_city <- read_csv("data/df_eofs_city.csv")
eofs <- read_csv("data/df_eofs.csv")

city_indexes <- city_indexes |> 
  clean_names() 
```


# Introduction 

Traditional approaches to analysing housing indexes, such as hedonic or repeat-sales models, can introduce selection bias or violate underlying assumptions. Moreover, they fail to capture key regional, social, or macroeconomic factors that play a significant role in driving housing price movements.

In the recent research Sijp et al. (2025) propose a new approach that applies Principal Component Analysis (PCA) to city-level housing indexes, enabling the extraction of key drivers of price movements and offering a deeper understanding of the forces shaping housing markets.

The PCA results show that the first three principal components capture much of the behaviour of local price indexes, as a linear combination of their time series explains most of the variance in the housing index. Nevertheless, the PCA-based linear model lacks robustness across different time windows, and its coefficient estimates must be derived directly from the PCA procedure.

Our exploratory research extends the PCA approach by addressing these limitations through a factor linear model, which uses time series data directly, with independent variables serving as proxies for the PCA-derived principal components.


# Research Structure 

The national trend (U) exhibits a close correspondence with PC1 (market), while the Brisbane–Sydney spread (δBS) aligns with PC2 (mining). Given that these principal components account for the majority of variance in the index, our preliminary analysis focuses on U and δBS, with subsequent extensions planned.

The research will focus on the following directions: 

* Examine the characteristics of U and δBS. 

* Evaluate whether the existing U-adjusted δBS should be employed in place of the “Brisbane on Sydney” spread derived from the bris ∼ syd regression for modelling purposes.

* Whether the δBS serves as a more stable measure than U in the factor model.

* Whether the coefficient δ provides a valid replacement for PC2.

* How well the factor model captures the variation in individual SA4 indexes.

* How the model can be extended to a time-dependent version using moving windows with evolving coefficients.


## Exploratory Analysis 

The exploratory analysis utilises visualisations to characterise the dynamics of the national trend (U) and the Brisbane–Sydney spread (δBS), thereby clarifying their underlying properties.

```{r}
factor_trend_ts <- factor_trends |>
  transmute(
    month_date = yearmonth(as.Date(month_date)),
    U = as.numeric(market),
    BS = as.numeric(mining)
  ) |>
  as_tsibble(index = month_date)

# Time-series autoplot
p1 <- factor_trend_ts |> autoplot(U) + labs(title = "U: National Trend", x = "Month", y = "Index")
p2 <- factor_trend_ts |> autoplot(BS) + labs(title = "δBS: Brisbane–Sydney Spread", x = "Month", y = "Index")
p1 + p2
```

**Time plots:** 

* U rises steadily from 2003 to 2012, transitions into a slower growth phase until 2019, then undergoes a sharp regime shift during 2020–2022 (the COVID period) followed by persistently elevated and volatile levels, with growth rates remaining time-varying throughout.

* δBS displays a prolonged, uneven rise from 2003 to 2012, followed by a sharp regime shift, then COVID-related fluctuations, with the level adjusting and showing time-varying patterns.

```{r}
# Seasonal plots
p3  <- factor_trend_ts |> gg_season(U) + labs(title = "Seasonal Plot: U", x = "Month", y = "Index")
p4 <- factor_trend_ts |> gg_season(BS) + labs(title = "Seasonal Plot: δBS", x = "Month", y = "Index")
p3 + p4
```

**Seasonal plots:**

* U has apparent within-year slopes being dominated by the strong upward trend; no systematic month-of-year effects.

* δBS shows little evidence of month-to-month seasonality, with no particular month standing out, though its overall level varies between years.

```{r}
# Seasonal subseries
p5 <- factor_trend_ts |> gg_subseries(U) + labs(title = "Seasonal Subseries: U", x = "Month", y = "Index")
p6 <- factor_trend_ts |> gg_subseries(BS) + labs(title = "Seasonal Subseries: δBS", x = "Month", y = "Index")
p5 + p6
```

**Seasonal sub-series plot:** 

* Each monthly panel of U shows a steady upward rise with mean value across months remaining similar, reinforcing that the series is driven more by trend than by seasonality.

* The δBS seasonal sub-series plot reinforces the lack of a dominant seasonal pattern, as the monthly profiles are similar in shape and the corresponding means remain relatively flat and close to zero.

```{r}
# ACF
p7  <- factor_trend_ts |> ACF(U) |> autoplot() + labs(title = "ACF: U", x = "Lag", y = "ACF")
p8 <- factor_trend_ts |> ACF(BS) |> autoplot() + labs(title = "ACF: δBS", x = "Lag", y = "ACF")
p7 + p8
```

**ACF plot:** 

* Both series has very high autocorrelation with slow decay across many lags, indicating strong dependence on many prior months, though the variation of δBS is much more bounded than U. 


## Engle–Granger Cointegration Test

We use the Engle–Granger procedure to test whether Brisbane and Sydney index levels are cointegrated, that is - whether each series is non-stationary but some linear combination is stationary, implying a stable long-run relationship.

The test statistic is –1.098, so we fail to reject the unit-root null. This result indicates no cointegration between the raw Brisbane and Sydney levels and the residuals are non-stationary, which means a single long-run equilibrium is not supported.

We therefore model a factor model and treat δBS as an informative second factor (a proxy for PC2), rather than assuming a tight long-run equilibrium between Brisbane and Sydney levels.

```{r}
# Build monthly series of levels
city <- city_indexes |>
  transmute(
    month = yearmonth(floor_date(as.Date(month_date), "month")),
    bris  = as.numeric(greater_brisbane),
    syd   = as.numeric(greater_sydney)
  ) |>
  as_tsibble(index = month) 

# Unit-root checks
adf_bris_lvl  <- ur.df(city$bris, type = "trend", selectlags = "AIC")
adf_syd_lvl   <- ur.df(city$syd,  type = "trend", selectlags = "AIC")
adf_bris_diff <- ur.df(diff(city$bris), type = "none", selectlags = "AIC")
adf_syd_diff  <- ur.df(diff(city$syd),  type = "none", selectlags = "AIC")

# Long-run regression
cn_lm <- lm(bris ~ syd, data = as.data.frame(city))  
alpha <- coef(cn_lm)[2]
ect   <- resid(cn_lm)  

# ADF on residuals 
adf_ect <- ur.df(ect, type = "none", selectlags = "AIC")
summary(adf_ect)
```


## Sydney-Brisbane Spread vs National Trend

To justify including δBS alongside the national trend U in the factor model, we need to show that δBS is more bounded over time, meaning it stays within a narrower range and has lower long-term volatility.

We approach this assumption from 3 angles:

* Method One uses past volatility and spread measures to compare past fluctuations in δBS and U. It is straightforward, does not rely on a model, and gives a clear historical picture.

* Method Two fits ARIMA models to both series and compares the width of 10-year forecast intervals. This gives a forward-looking view using well-known time series methods.

* Method Three runs simulation-based forecasts to estimate the possible future range of each series. This can capture uncertainty beyond ARIMA’s limits and show patterns like non-linear or extreme swings.

Combined, these methods integrate descriptive analysis, statistical modelling, and stochastic simulation to rigorously assess whether δBS is more bounded than U.

### 1. Statistical Comparison 

In the first part, we compared δBS and U using overall statistics and rolling-window measures.

The global summary covered standard deviation, interquartile range, median absolute deviation, and total range to capture different aspects of spread.

We then used 12-month and 24-month rolling windows: 12 months to match a typical year and 24 months to smooth short-term noise while showing medium-term trends.

For clarity, we focused on two key plots: the 12-month rolling standard deviation for short-run volatility, and the 24-month rolling range for longer-run swings.

Finally, we calculated the proportion of time in which δBS had a lower spread than U, giving a simple measure of how often it was more bounded.

```{r}
# Load df 
factor_trends_ana <- factor_trends |>
  select(month_date, U = market, BS = mining) 

# Global comparison - full period 
global_summary <- factor_trends_ana |>
  summarise(
    sd_U = sd(U),
    sd_BS = sd(BS),
    var_U = var(U),
    var_BS = var(BS),
    iqr_U = IQR(U),
    iqr_BS = IQR(BS),
    range_U = diff(range(U)),
    range_BS = diff(range(BS)),
    mad_U = mad(U, center = median(U)),
    mad_BS = mad(BS, center = median(BS))
  ) 

global_ratio <- global_summary |>
  mutate(
    sd_ratio_BS_over_U = sd_BS / sd_U,
    iqr_ratio_BS_over_U = iqr_BS / iqr_U,
    mad_ratio_BS_over_U = mad_BS / mad_U,
    rng_ratio_BS_over_U = range_BS / range_U
  ) |>
  select(sd_ratio_BS_over_U,
         iqr_ratio_BS_over_U,
         mad_ratio_BS_over_U,
         rng_ratio_BS_over_U) 

kable(global_ratio, caption = "Global Summary Statistics") 

# Summary tables 
#print(global_summary) 
#print(global_ratio)
```

The global ratios are all well below 1, meaning δBS has consistently lower spread than U across all four measures. This supports δBS being more bounded overall.

```{r}
# Rolling window config (12 and 24 months) 
w12 <- 12
w24 <- 24

# Functions for rolling statistics (SD, IQR, Range)
roll_sd   <- function(x, k)
  slide_dbl(x, sd, .before = k - 1, .complete = TRUE)

roll_iqr  <- function(x, k)
  slide_dbl(x, IQR, .before = k - 1, .complete = TRUE)

roll_rng  <- function(x, k)
  slide_dbl(x, function(vec)
    diff(range(vec)), .before = k - 1, .complete = TRUE)

# Compute rolling statistics
roll_stats <- factor_trends_ana |>
  mutate(
    # 12-month window
    sd12_U = roll_sd(U, w12),
    iqr12_U = roll_iqr(U, w12),
    rng12_U = roll_rng(U, w12),
    sd12_BS = roll_sd(BS, w12),
    iqr12_BS = roll_iqr(BS, w12),
    rng12_BS = roll_rng(BS, w12),
    # 24-month window
    sd24_U = roll_sd(U, w24),
    iqr24_U = roll_iqr(U, w24),
    rng24_U = roll_rng(U, w24),
    sd24_BS = roll_sd(BS, w24),
    iqr24_BS = roll_iqr(BS, w24),
    rng24_BS = roll_rng(BS, w24)
  )
```

```{r}
# Rolling 12-month SD plot 
sd12_long <- roll_stats |>
  select(month_date, sd12_U, sd12_BS) |>
  pivot_longer(-month_date, names_to = "series", values_to = "sd12") 

ggplot(sd12_long, aes(month_date, sd12, color = series)) +
  geom_line() +
  labs(
    title = "Rolling 12-month Standard Deviation (SD)",
    subtitle = "Lower values show less volatility over a 12-month period",
    x = "Year",
    y = "SD"
  ) +
  theme_minimal()

# Rolling 24-month Range plot 
rng24_long <- roll_stats |>
  select(month_date, rng24_U, rng24_BS) |>
  pivot_longer(-month_date, names_to = "series", values_to = "rng24") 

ggplot(rng24_long, aes(month_date, rng24, color = series)) +
  geom_line() +
  labs(
    title = "Rolling 24-month Range",
    subtitle = "Wider range means bigger swings over the period",
    x = "Year", y = "Range"
  ) +
  theme_minimal()

# Summary table 
porp_summary <- tibble(
  period = c("12-month", "24-month"),
  prop_lower_sd = c(
    mean(roll_stats$sd12_BS < roll_stats$sd12_U, na.rm = TRUE),
    mean(roll_stats$sd24_BS < roll_stats$sd24_U, na.rm = TRUE)
  ),
  prop_lower_iqr = c(
    mean(roll_stats$iqr12_BS < roll_stats$iqr12_U, na.rm = TRUE),
    mean(roll_stats$iqr24_BS < roll_stats$iqr24_U, na.rm = TRUE)
  ),
  prop_lower_rng = c(
    mean(roll_stats$rng12_BS < roll_stats$rng12_U, na.rm = TRUE),
    mean(roll_stats$rng24_BS < roll_stats$rng24_U, na.rm = TRUE)
  )
)

kable(porp_summary, digits = 3, caption = "Proportion of Time δBS < U in Rolling Windows")
```

While the rolling-window plots and statistics give a more detailed picture: 

* The 12-month rolling standard deviation plot shows that δBS is often less volatile than U, but not consistently (occasional spikes narrow the gap).

* The 24-month rolling range plot shows δBS has wider swings at times, but also periods where it is more stable than U, highlighting its tendency to avoid large swings over longer periods.

* δBS has a lower spread than U in around 38.6% of the time for 12-month windows and 41.0% for 24-month windows, indicating it is more bounded (however, less than half the time) in rolling windows.

### 2. ARIMA Forecasting Comparison

Following the descriptive analysis, in this section, we take a model-based approach to assess boundedness. 

We applied auto ARIMA to both δBS and U time series to produce 10-year ahead forecasts, with the sole purpose of comparing their long-term prediction interval widths. Using auto selection ensures each series is modelled appropriately without over-focusing on manual parameter tuning, keeping the emphasis on interval comparison as a measure of future boundedness.

```{r}
# Transform df to tsibble 
factor_trends_ts <- factor_trends |>
  transmute(date = as.Date(month_date),
            U  = market,
            BS = mining) 

start_year  <- year(min(factor_trends_ts$date))
start_month <- month(min(factor_trends_ts$date))
ts_U  <- ts(factor_trends_ts$U,  frequency = 12, start = c(start_year, start_month))
ts_BS <- ts(factor_trends_ts$BS, frequency = 12, start = c(start_year, start_month))

# Fit auto ARIMA
fit_U  <- auto.arima(ts_U,  stepwise = FALSE, approximation = FALSE)
fit_BS <- auto.arima(ts_BS, stepwise = FALSE, approximation = FALSE)

# Forecast - 10 years
h <- 120
fc_U  <- forecast(fit_U,  h = h, level = c(80, 95))
fc_BS <- forecast(fit_BS, h = h, level = c(80, 95))

# Compute average forecast intervals 
fc_int <- function(fc, level) {
  col <- fc$level == level
  mean(fc$upper[, col] - fc$lower[, col])
}

summary_fc_int<- tibble(
  period_months = h,
  level = c(80, 95),
  mean_int_U = c(fc_int(fc_U, 80), fc_int(fc_U, 95)),
  mean_int_BS = c(fc_int(fc_BS, 80), fc_int(fc_BS, 95))
) 

kable(summary_fc_int, caption = "Average Forecast Intervals for δBS and U")

# Plot the forecasts
autoplot(fc_U)
autoplot(fc_BS) 

# Residuals seem like white noise - bell shaped + no autocorrelation from ACF 
#checkresiduals(fit_U) 
#checkresiduals(fit_BS)
```

From the average 10-year forecast intervals, the δBS spread has consistently narrower prediction ranges compared to the U trend, suggesting it is likely to stay more contained over the next decade, as supported by both the summary table and the visual patterns in the forecast plots.

### 3. Simulation-Based Forecasting

Next, we apply simulation-based forecasting through Monte Carlo methods, conducting simulations from the ARIMA models of U and δBS. We generate 5000 samples over the same horizon to compare their dispersion and assess the boundedness of δBS relative to U. 

This approach enables the capture of more complex dynamics and potential non-linearities that standard ARIMA models may overlook.

```{r}
set.seed(123)

# Simulation 
n <- 5000 
sim_U  <- replicate(n, simulate(fit_U,  nsim = h, future = TRUE, bootstrap = TRUE))
sim_BS <- replicate(n, simulate(fit_BS, nsim = h, future = TRUE, bootstrap = TRUE))

# Last observed level - MAD comparison 
max_dev_stats <- function(sim, last) {
  col_max_dev <- apply(abs(sim - last), 2, max)
  c(
    median_max_dev = median(col_max_dev),
    p90_max_dev    = unname(quantile(col_max_dev, 0.90))
  )
}

# Historical 90% bands - stay in band prob 
stay_prob <- function(sim, lo, hi) {
  col_min <- apply(sim, 2, min)
  col_max <- apply(sim, 2, max)
  mean(col_min >= lo & col_max <= hi)
}

# MC bands and widths
qdf <- function(mat) {
  hh <- nrow(mat)
  tibble(
    step = seq_len(hh),
    p50  = apply(mat, 1, median),
    lo80 = apply(mat, 1, quantile, probs = 0.10),
    hi80 = apply(mat, 1, quantile, probs = 0.90),
    lo95 = apply(mat, 1, quantile, probs = 0.025),
    hi95 = apply(mat, 1, quantile, probs = 0.975)
  ) |>
    mutate(width80 = hi80 - lo80,
           width95 = hi95 - lo95)
}
```

```{r}
# End of horizon fan widths
fan_U  <- qdf(sim_U)  |> mutate(series = "U")
fan_BS <- qdf(sim_BS) |> mutate(series = "δBS")
bands_all <- bind_rows(fan_U, fan_BS)

end_widths <- bands_all |>
  group_by(series) |>
  filter(step == max(step)) |>
  summarise(width80_end = first(width80),
            width95_end = first(width95),
            .groups = "drop")

kable(end_widths, caption = "End of Horizon Fan Widths for δBS and U")
```

The fan width at the end of the forecast horizon indicates that the uncertainty of U is approximately nine times greater than that of δBS.

```{r}
# Stay in historical 90% band prob 
hist_band_U  <- quantile(as.numeric(fit_U$x), c(0.05, 0.95))
hist_band_BS <- quantile(as.numeric(fit_BS$x), c(0.05, 0.95))
pr_U  <- stay_prob(sim_U, hist_band_U[1], hist_band_U[2])
pr_BS <- stay_prob(sim_BS, hist_band_BS[1], hist_band_BS[2])

stay_prob_tbl <- tibble(
  series = c("U", "δBS"),
  stay_90 = c(pr_U, pr_BS)
)

kable(stay_prob_tbl, caption = "Probability of Staying in Historical 90% Band")
```

δBS exhibits a 26.0% probability of remaining within its historical 90% confidence band, whereas U demonstrates a 0% probability. 

```{r}
# MAD over horizon 
last_U  <- tail(as.numeric(fit_U$x),  1)
last_BS <- tail(as.numeric(fit_BS$x), 1)
md_U  <- max_dev_stats(sim_U,  last_U)
md_BS <- max_dev_stats(sim_BS, last_BS)

max_dev_tbl <- tibble(
  series          = c("U", "δBS"),
  median_max_dev  = c(md_U["median_max_dev"],  md_BS["median_max_dev"]),
  p90_max_dev     = c(md_U["p90_max_dev"],     md_BS["p90_max_dev"])
)

kable(max_dev_tbl, caption = "Maximum Deviation Statistics for δBS and U")
```

Over the forecast horizon, the mean absolute deviation indicates that δBS exhibits both a lower median deviation and a lower 90th-percentile maximum deviation compared to U.
